---
title: "V506 Lab 5"
author: "Luis Navarro"
date: "Spring 2024"
output:
  slidy_presentation: default
  #ioslides_presentation: default
subtitle: Data Reshape and Random Variables
---


```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r, echo=FALSE, eval=TRUE}
# Clean the environment 
rm(list=ls())
setwd("/Users/luisenriquenavarro/Library/CloudStorage/OneDrive-IndianaUniversity/V506/Lab 5")
library(pacman)
p_load(tidyverse, rmarkdown, dplyr, ggplot2, descriptr)
```

# Example: GDP States 

- Sometimes data does not comes in the format we need it to work. 

- To exemplify this, we use data from the Bureau of Economic Analysis on state's Gross Domestic Product (GDP.)

- Get the data [here](https://www.bea.gov/data/gdp/gdp-state) or download it from Canvas. 

- This data set has information on state's GDP. 

- Data: SAGDP9N: Real GDP by state: All industry total (Millions of chained 2012 dollars)

```{r, eval = TRUE, echo = TRUE}
gdp_states <- read.csv(file = "gdp_states.csv", header = TRUE) %>% tibble() 
head(gdp_states)
```


# Data Formats: Wide and Long

- Data could be presented in one of two formats. 

- Long vs wide format. 

```{r, eval = TRUE, echo = FALSE}
gdp_wide <- gdp_states

gdp_long <- gdp_states %>% gather(key = "year", value = "real_gdp", -c(GeoName,GeoFips)) 

```

- **Wide Format:** contains values that do not repeat on the first column. 


```{r, eval = TRUE, echo = TRUE}
gdp_wide %>% head(n = 6)
```


- **Long Format:** contains values that do repeat on the first column. 

```{r, eval = TRUE, echo = TRUE}
gdp_long %>% head(n = 6)
```


# Reshape data with dplyr: gather and spread

- To reshape the data set we use the functions *gather* and *spread*. 

- **gather:** from wide to long (pivot_longer)
- **spread:** from long to wide (pivot_wider)

- Both the gather and spread functions will create a new data frame, so we need to specify the names of the new variables. 

- Syntax *gather* function. 

```{r, echo = TRUE, eval = FALSE}
gather(data, 
       key = "key", ## New Column Created 
       value = "value", ## Values
       -..., ## selection of columns that identify observations in the data
       )
```

- gather general syntax: notice the columns (pivots) need to be specified by using the "-" symbol

```{r, eval = FALSE, echo = TRUE}
df_long <- df %>% 
  gather(key = "variable", 
         value = "level", -id) 
```


- Syntax *spread* function

```{r, echo = TRUE, eval = FALSE}
spread(data, 
       key = "key", ## name of the variable that will be the columns
       value = "value", ## Values it takes 
       )
```

- Notice that the spread function does not requires the selection of columns that identify observations in the data .

- Why? Once you determined the key and value, then the rest of the variables identify each unique observation in the data. 

# Example: Reshape GDP data 

- Let's express the GDP data on long format. 

```{r, eval = TRUE, echo = TRUE}
gdp_long <- gdp_states %>% 
  gather(key = "year", value = "real_gdp", -c(GeoName,GeoFips)) %>% 
   ## Intermediate Step to clean year variable 
  mutate(year = substr(year,2,nchar(year)) %>% as.double()) %>% 
  # Keep only states data 
  filter(GeoFips >0 &GeoFips < 90000) %>% 
  # Rename variables 
  rename(state = GeoName)
```

- With the data in this format now we can easily compare states GDP. 

- Now let's do an example of reshape wide 

```{r}
gdp_wide <- gdp_long %>% 
  spread(key = year, # name of the variable that will be columns 
         value = real_gdp)

gdp_wide %>% head()
```



# Data Merging 

- Sometimes you need to merge datasets for your analysis. 

- Say you want to compute GDP per capita. That is, GDP divided by population. 

- We need to add a column with the population.

```{r, eval = TRUE, echo = TRUE}
states_pop_long <- read.csv(file = "state_population_long.csv", header = TRUE) %>% tibble() %>% select(-X)
head(states_pop_long)

# Define data for merge 
gdp_long2020 <- gdp_long %>% 
  filter(year >= 2020) 
```

# Left Join 

- Dyplyr has `join` functions to merge data sets. 

- Notation: $X$ is your initial data set. $Y$ is the data with the columns you are adding. 

- left_join($X$) adds columns to the left of $X$. It preserves all the observations on such dataset. 

- To perform the merge we need to specify the variables in common between the two sets: the merging criteria. 

- Also, we need to specify the type of relationship between the data sets. 

- One-to-one: for each observation in $X$, there is only one observation in $Y$ that matches the merging criteria. 

    - Ex: merging a state-year dataset with another state-year dataset.

- Many-to-one: for each observation in $X$, there are many observations in $Y$ that matches the merging criteria. 

    - Ex: merging a state-year dataset with a state dataset.

- Many-to-many: several observations in $X$ could be matched with several observations $Y$ for the same merging criteria. (Use it carefully)


```{r, echo = TRUE, eval = FALSE}
# syntax code 
merged_data1 <- data_x %>% 
  left_join(data_y, by = c("var1", ..., "var2"), 
            relationship = "one-to-one")


merged_data2 <- data_x %>% 
  left_join(data_y, by = c("var1"), 
            relationship = "many-to-one") # Many observations in x, will receive the same value of y 
```

# Example 

```{r}
states_data <- gdp_long2020 %>% 
  # Merge population data 
  left_join(states_pop_long, 
            by = c("state", "year"), #merge by state and year
            relationship = "one-to-one") 

```

- Compute GDP per capita with the population data. 

```{r}
states_data <- states_data %>% 
  # multiply by one million, to express everything in US dollars.
  mutate(gdp_per_capita = 1000000*real_gdp/population)

states_data %>% head()
```


- Extra: compute the average GDP per capita for each year. 

```{r}
states_data %>% 
  # Compute the average across states, to get observations for each year 
  group_by(year) %>% 
  summarize(gdp_per_capita = mean(gdp_per_capita, na.rm = TRUE))

```

# Simulating Random Variables 

- Statistical analysis requires understanding how probability distributions work. 

- For that, we will cover how to simulate them using R. 

- For simplicity, we will only work with the normal distribution. 


# Example 

- Let's create a function that takes a random sample from a normal distribution. 

- Parameters: number of observations, and the moments of the distribution (mean and standard deviation)

```{r}
create_random_normal <- function(n, mean, sd) {
  set.seed(1234)
  # Take a sample of n observations from a normal distribution with mean and sd 
  random_sample <- rnorm(n = n, mean = mean, sd = sd)
  # Obtain the density of the sample we just simulated 
  normal_density <- dnorm(random_sample, mean = mean, sd = sd)
  # Save the output in a data frame 
  df <- tibble(id = seq(1:n), 
               values = random_sample, 
               density = normal_density)
  return(df)
}
```

- Use the function to simulate 1000 draws from a normal distribution with mean = 1 and sd = 2

```{r}
sample1 <- create_random_normal(n = 1000, 
                                mean = 1, 
                                sd = 2)

sample1 %>% head()
```
- Visualize this using a ggplot graph. 

```{r}
normal_density_graph <- sample1 %>% 
  # create a ggplot object
  ggplot() + 
  geom_line(mapping = aes(x = values, y = density), col = "black") + 
  labs(y = "density", x = "values", title = "Probability Density Function of a Normal Distribution") + 
  # add vertical line equal to the mean
  geom_vline(xintercept = 1, col = "firebrick", linetype = "dashed") + 
  theme_bw()

normal_density_graph
```

- Extra: compare using a histogram  

```{r}
histogram_plot <- sample1 %>% 
  # create a ggplot object
  ggplot(mapping = aes(x = values)) + 
  geom_histogram(col = "black", fill = "steelblue1", bins = 20) +
  labs(y = "count of observations", x = "values", title = "Probability Density Function of a Normal Distribution") + 
  # add vertical line equal to the mean
  geom_vline(xintercept = 1, col = "firebrick", linetype = "dashed") + 
  theme_bw()


histogram_plot
```

- Add the normal density line to compare. 

- We need to modify the code above to show the histogram, but with the units from the probability density function. 

- Note: keep in mind this comparison is between the empirical (observed) distribution from the data, and a theoretical (unobserved) 

```{r}
histogram_plot_with_normal_curve <- sample1 %>% 
  # create a ggplot object
    # Set the mapping to tell R the y axis is expressed in units from the density function
  ggplot(mapping = aes(x = values, y = ..density..)) + 
  # Create the histogram 
  geom_histogram(col = "black", fill = "yellow1", bins = 20, alpha = 0.5) +
  # To add the normal curve, we need to specify again the aesthetic mapping
  geom_line(mapping = aes(x = values, y = density), col = "steelblue3") + 
  labs(y = "density", x = "values", title = "Probability Density Function of a Normal Distribution") + 
  # add vertical line equal to the mean
  geom_vline(xintercept = 1, col = "firebrick", linetype = "dashed") + 
  theme_bw()


histogram_plot_with_normal_curve
```

# Extra: States GDP Graph 

```{r, eval = TRUE, echo = TRUE}
gdp_graph <- gdp_long %>% 
  # Filter some states to show
  filter(state == "California" | state == "Texas" | state == "New York") %>% 
  # Create log gdp variable to ease comparison 
  mutate(log_gdp = log(real_gdp)) %>% 
  ggplot(mapping = aes(x = year, y = log_gdp, 
                       col = state)) +   # Each state gets an individual color
  geom_line() +  # Draw a line plot 
  labs(x = "Year", y = "Log GDP") 
```

- *Quick Tip:* functions allow you to automatize processes. A useful one is formatting your graphs. 

```{r, eval = TRUE, echo = TRUE}
# Function that allows you to format all your plots 
# Define Fontsize outside the function (you can plug it as an addtional parameter if you like)
fontsize = 12 
# Function: 
format_plot <- function(graph, title, subtitle){
  # Format the Graph 
  formatted_plot <- graph  + 
           theme_bw() + 
           labs(title = title, 
                subtitle = subtitle) + 
           scale_x_continuous(n.breaks=5) +
           scale_y_continuous(n.breaks=5) +
           theme(axis.text.x = element_text(angle = 90, size = fontsize), 
                 axis.text.y = element_text(angle = 0, size = fontsize),
                 axis.title.x = element_text(size = fontsize),
                 axis.title.y = element_text(size = fontsize),
                 legend.text = element_text(size = fontsize -2),
                 legend.title = element_blank(),
                 plot.title = element_text(angle = 0, size = fontsize + 3, face = "bold"))
  
  return(formatted_plot)
}
```

```{r}
# show formatted plot 
format_plot(graph = gdp_graph, 
            title = "Real GDP Growth: Texas, California, and New York", 
            subtitle = "Log (Real GDP)")
```


# Extra: Add Kernel Density Line to Histogram 

- Alternatively, you can add the empirical density function. 


```{r}
histogram_plot_with_density <- sample1 %>% 
  # Set the mapping to tell R the y axis is expressed in units from the density function
  ggplot(mapping = aes(x = values, y = ..density..)) + 
  # Create the histogram 
  geom_histogram(col = "black", fill = "white") +
  # Add the kernel density of the own data 
  geom_density(col = "steelblue") + 
  labs(y = "density", x = "values", title = "Probability Density Function of a Normal Distribution") + 
  # add vertical line equal to the mean
  geom_vline(xintercept = 1, col = "firebrick", linetype = "dashed") + 
  theme_bw()


histogram_plot_with_density
```


# Extra Example: Density from Real Data 

- Let's analyze the distribution of GDP per capita. 

- We want to check if it is distributed normal. 

- First, compute the mean and standard deviation. 

```{r}
# Set the moments 
gdp_mean = mean(states_data$gdp_per_capita, na.rm = TRUE)
gdp_sd = sd(states_data$gdp_per_capita, na.rm = TRUE)
gdp_obs = length(states_data$gdp_per_capita)

# Create simulation of a sample from a normal distribution 
sample_normal_gdp <- create_random_normal(
  n = gdp_obs, 
  mean = gdp_mean, 
  sd = gdp_sd
)

# Add it to the current state data 
states_data_with_normal <- states_data %>% 
  # Create id variable to do the merge
  mutate(id = seq(1:gdp_obs)) %>% 
  left_join(sample_normal_gdp, by = "id", relationship = "one-to-one") %>% 
  rename(simulated_gdp = values)

head(states_data_with_normal)
```


```{r}
distribution_gdp_pc <- states_data_with_normal %>% 
  # Set the mapping to tell R the y axis is expressed in units from the density function
  ggplot(mapping = aes(x = real_gdp, y = ..density..)) + 
  # Add the kernel density of the own data 
  geom_density(col = "firebrick") + 
  # Add normal density curve for comparison
  geom_line(mapping = aes(x = simulated_gdp, y = density), col = "steelblue3") + 
  labs(y = "density", x = "values", title = "Probability Density Function of a Normal Distribution") + 
  # add vertical line equal to the mean
  geom_vline(xintercept = gdp_mean, col = "green", linetype = "dashed") + 
  theme_bw()


distribution_gdp_pc
```


# Extra Example: Merge using base R

-   merge() allows you to combine to data frames using common colums or row names--to join two separate data frames. 
-   merge(x,y,...)-- the data frames you'd like to merge. 
-   You also specify "by". This can be "by.x=", "by.y=", or "by=" to specify what you are going to be matching on. 
-   "all=" allows you to specify if you want to merge all observations of each data frame.

**Example:** Let's create some fake data that we can use:
```{r}
income_df = tibble(id = c(1:100), 
                   urban = sample(c(0,1), replace=TRUE, size=100), 
                   income = sample(c(0, 20000:100000), replace=TRUE, size=100))

income_df <- income_df %>% arrange(by_group=-id)

health_df = tibble(id = c(1:100), 
                  health_spending  = sample(c(0:20000), replace=TRUE, size=100))
```

- sample() takes a sample of the specified size (size=n) from the elements in x with or without replacement. 
- I wanted to randomly assign (0 and 1) as a binary variable to be if the person lives in an urban area or not. 
- Notice that both data frames have a common variable, *id*.


# Extra Example: Merge using base R

```{r}
df1 = merge(income_df, health_df, by="id")
head(df1)
```

- Now suppose there is a data frame that only has data for the first 30 observations and has a dummy variable if they had an ER visit:
```{r}
er_visits = tibble(id = c(1:30), er_visit = sample(c(1,0), replace=TRUE, size=30))
er_visits
```

- Merge to *er_visits* to *df1*:

```{r}
df2 = merge(df1, er_visits, by = "id")
head(df2, n=10L)
nrow(df2)
```

- Notice that *df2* has only 30 observations, so *merge()* restricted the sample to the first 30 id's with ER information.

- We can force it to merge on *all* (all observations from both datasets):
```{r}
df3 = merge(df1, er_visits, by = "id", all = TRUE)
```

- Or merge on *all.x* (Keep all observations from data frame x):
```{r}
df4 = merge(df1, er_visits, by="id", all.x = TRUE)
```

- Or merge on *all.y* (Keep all observations from data frame y):
```{r}
df5 = merge(df1, er_visits, by="id", all.y = TRUE)
```

